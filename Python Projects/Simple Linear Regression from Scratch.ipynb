{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference material:Week 4 PPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method that computes standard deviation of a variable\n",
    "import math\n",
    "def ComputeStandardDeviation(listOfValues,mean):\n",
    "    valuesCount = len(listOfValues)\n",
    "    totalSum = 0\n",
    "    for i in listOfValues:\n",
    "        difference = i - mean\n",
    "        differenceSquare = difference*difference\n",
    "        totalSum = totalSum + differenceSquare\n",
    "    variance = totalSum/valuesCount\n",
    "    standardDeviation = math.sqrt(variance)\n",
    "    return standardDeviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method that computes mean of a variable\n",
    "def ComputeMean(listOfValues):\n",
    "    valuesCount = len(listOfValues)\n",
    "    totalSum = 0\n",
    "    for i in listOfValues:\n",
    "        totalSum = totalSum + i\n",
    "    mean = totalSum/valuesCount\n",
    "    return mean\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method that computes correlation coefficient between X and Y\n",
    "#X and Y should have same lenght. More the absolute value of correlation coeffiecient 'r', stronger the relationship\n",
    "#Value lies between -1 and +1. '0' value means no relationship\n",
    "def ComputeCorrelationValue(listX,listY):\n",
    "    meanOfX = ComputeMean(listX)\n",
    "    meanOfY = ComputeMean(listY)\n",
    "    stdDevOfX = ComputeStandardDeviation(listX,meanOfX)\n",
    "    stdDevOFY = ComputeStandardDeviation(listY,meanOfY)\n",
    "    valuesCount = len(listX)\n",
    "    \n",
    "    totalSum = 0\n",
    "    for i in range(0,valuesCount):\n",
    "        #terms are divide by staddev to normalize it\n",
    "        termX = (listX[i] - meanOfX)/stdDevOfX\n",
    "        termY = (listY[i] - meanOfY)/stdDevOfY\n",
    "        totalSum = totalSum + (termX*termY)\n",
    "    \n",
    "    correlationCoefficient = totalSum/(valuesCount-1)\n",
    "    return correlationCoefficient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate parameters using Least Square estimates formula\n",
    "def EstimateParameterByOLS(independentVariableX,dependentVariableY,meanX,meanY):\n",
    "    valuesCount = len(independentVariableX)\n",
    "    numerator = 0\n",
    "    denomenator = 0\n",
    "    for i in range(0,valuesCount):\n",
    "        numerator = numerator + ((independentVariable[i]-meanX)*(dependentVariable[i]-meanY))\n",
    "        denomenator = denomenator + ((independentVariable[i]-meanX)^2)\n",
    "    parameterSlope = numerator/denomenator\n",
    "    \n",
    "    parameterInercept = meanY - (parameterSlope*meanX)\n",
    "    return parameterSlope,parameterIntercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate parameters using gradient descent method\n",
    "def EstimateParameterByGradientDescent(intialSlope,initialIntercept,learningRate,independentVariableX,dependentVariableY):\n",
    "    valuesCount = len(independentVariableX)\n",
    "    partialDerivativeBySlope = 0\n",
    "    partialDerivativeByIntercept = 0\n",
    "    while(partialDerivativeBySlope ==0 and partialDerivativeByIntercept==0):\n",
    "        \n",
    "        for i in range(0,valuesCount):\n",
    "            partialDerivativeBySlope = partialDerivativeBySlope + (2*(dependentVariableY[i]-(intialIntercept+(initialSlope*independenVariableX[i]))))*independentVariableX[i]\n",
    "            partialDerivativeByIntercept = partialDerivativeByIntercept + (2*(dependentVariableY[i]-(intialIntercept+(initialSlope*independenVariableX[i]))))\n",
    "        updatedSlope = intialSlope - (learningRate*partialDerivativeBySlope)\n",
    "        updatedIntercept = initalIntercept - (learningRate*partialDerivativeByIntercept)\n",
    "        intialIntercept = updatedIntercept\n",
    "        initialSlope = updatedSlope\n",
    "    return updatedSlope,updatedIntercept\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goodness to fit test: F test for variances\n",
    "#Relevant only for multiple linear regression because it tests whether atleast one of the X variables is significant for the model.\n",
    "#And for simple LR there is only 1 X variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goodness to fit test: Coefficient of determination i.e. Rsquare\n",
    "#Rsquare = regression sum of suqares (SSR)/ total sum of squares (SST)\n",
    "#Higehr the value of RSquare,more variantion of Y can be explained by variation in X (i,e. better fitted model)\n",
    "def ComputeRSquare(ActualValuesY,PredictedValuesY):\n",
    "    actualMeanY = ComputeMean(ActualValuesY)\n",
    "    valuesCount = len(ActualValuesY)\n",
    "    \n",
    "    SSR = 0\n",
    "    SST = 0\n",
    "    for i in range(0,valuesCount):\n",
    "        SSR = SSR + ((PredictedValuesY[i] - actualMeanY)^2)\n",
    "        SST = SST + ((ActualValuesY[i] - actualMeanY)^2)\n",
    "    RSquare = SSR/SST\n",
    "    return RSquare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
